{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "machine_learning_comment_classification_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YJKWHa7t44vU"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89eca123f70e4a638982bb73e5943a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6b992da334554af9b2d8c9aee825780a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b6834c550584645a28bcca03ea88460",
              "IPY_MODEL_90760bca89de4d259ca6886026a85719"
            ]
          }
        },
        "6b992da334554af9b2d8c9aee825780a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b6834c550584645a28bcca03ea88460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7801f84966246959321a1eb1dcf9444",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bce632e04e614c1884728d084a01422f"
          }
        },
        "90760bca89de4d259ca6886026a85719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6892fce594394d4e9445c23031b176b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:11&lt;00:00, 38.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1a3d5666048405681f0be25996cbc49"
          }
        },
        "e7801f84966246959321a1eb1dcf9444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bce632e04e614c1884728d084a01422f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6892fce594394d4e9445c23031b176b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1a3d5666048405681f0be25996cbc49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cf6159251a24335a1d764d805a7d513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_487d77148bb24a58a362a6d4260d9980",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03616adac4d9413089321a30583328bd",
              "IPY_MODEL_15b53eaeac8141f79a9147888f382653"
            ]
          }
        },
        "487d77148bb24a58a362a6d4260d9980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03616adac4d9413089321a30583328bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_444699ccb73a4ba28bd5efe85de07690",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_384e2517fd1646f0b5a9b30cf72b50fe"
          }
        },
        "15b53eaeac8141f79a9147888f382653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_24ad8a3610aa439ab7f4f4d0b947f45d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 42.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b0bad460383454eaedab2046a810124"
          }
        },
        "444699ccb73a4ba28bd5efe85de07690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "384e2517fd1646f0b5a9b30cf72b50fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24ad8a3610aa439ab7f4f4d0b947f45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b0bad460383454eaedab2046a810124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "316534e3378a4fd0aa684bb17d3d5659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca54398238cd469a858a280c166e2a81",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_efe566cf0ac843b5988dc30e08f6ce7e",
              "IPY_MODEL_519b98f6ee9043ff8f3e8f6dced4aba7"
            ]
          }
        },
        "ca54398238cd469a858a280c166e2a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efe566cf0ac843b5988dc30e08f6ce7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e978808800d24981805def710e4fb900",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72819b3c6d064642a6a3c7532d675f56"
          }
        },
        "519b98f6ee9043ff8f3e8f6dced4aba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a98a0aae76ae4eaa8806df70fcae6186",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 174kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f5f3a56b12742e7a50ee5ace9f9f011"
          }
        },
        "e978808800d24981805def710e4fb900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72819b3c6d064642a6a3c7532d675f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a98a0aae76ae4eaa8806df70fcae6186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f5f3a56b12742e7a50ee5ace9f9f011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b59af45011274f6abfa7058b66360f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d55415f92024d0287b04ca0d6e1ddfb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_da5877cc7c164274bc9c38d92aa43cdd",
              "IPY_MODEL_6625d01831ee4b7e8bea4c6cda153fbd"
            ]
          }
        },
        "7d55415f92024d0287b04ca0d6e1ddfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da5877cc7c164274bc9c38d92aa43cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3f0d293783746168a47578ebe49330b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_657855eddf0a43408dc87c5b6ac4fef4"
          }
        },
        "6625d01831ee4b7e8bea4c6cda153fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_adbafa8e19e84b2d9f852171c9249368",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 776kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c91d50b238224ae29046936bd5bcec47"
          }
        },
        "c3f0d293783746168a47578ebe49330b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "657855eddf0a43408dc87c5b6ac4fef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adbafa8e19e84b2d9f852171c9249368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c91d50b238224ae29046936bd5bcec47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaXPeXOWnoq-"
      },
      "source": [
        "# Машинное обучение для текстов: Классификация комментариев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVHIJHcs44pH"
      },
      "source": [
        "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
        "\n",
        "### Инструкция по выполнению проекта\n",
        "\n",
        "1. [Загрузите и подготовьте данные](#1)\n",
        "2. Обучите разные модели. \n",
        "3. Сделайте выводы.\n",
        "\n",
        "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
        "\n",
        "### Описание данных\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "C-B1-nO244pJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ddd374-822e-4de0-b882-90096f788d8f"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 15.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 13.0MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 12.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 9.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 10.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 10.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 35.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4ffd823cd8ee271f4ef5c39c7aa3f6651c519185098a16b3d36ed4413f8b1170\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO4TIoHj44pX"
      },
      "source": [
        "<a id=\"1\"></a>\r\n",
        "# 1. Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9j-tQOO44pY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.stem import SnowballStemmer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "# for BERT\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import tensorflow as tf\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68QasnWN44pd"
      },
      "source": [
        "# from io import BytesIO\n",
        "# import requests\n",
        "# spreadsheet_id = '1TLd-iskswKVcWjdNfZtwoTjVIM4OH7w-'\n",
        "# file_name = 'https://docs.google.com/spreadsheets/d/{}/export?format=csv'.format(spreadsheet_id)\n",
        "# r = requests.get(file_name)\n",
        "# df = pd.read_csv(BytesIO(r.content), sep=',')\n",
        "# df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ3xra5BJcdd"
      },
      "source": [
        "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\r\n",
        "# df = df.sample(n = 1000, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-40-RhjO44pk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "dbf6291f-4e0a-42e7-db06-74b3b3773579"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24915</th>\n",
              "      <td>YOU ARE A FAT, GEEKY PRICK WHO HAS NOTHING TO ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75819</th>\n",
              "      <td>Agent X2: Basically thanks - with a 'little' m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53891</th>\n",
              "      <td>Why are my posts being deleted? \\n\\nI have tri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154159</th>\n",
              "      <td>\"\\n\\n Controlled Demolitions and Common Sense ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13040</th>\n",
              "      <td>I do not understand your reply.  //Blaxthos ( ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119965</th>\n",
              "      <td>FUCKASS  ople like him... Thanks. I hate peopl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149832</th>\n",
              "      <td>I agree, as much as humanly possible, to avoid...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68147</th>\n",
              "      <td>REDIRECT Talk:Scooby-Doo! WrestleMania Mystery</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39863</th>\n",
              "      <td>\"\\n Not done: This is not supported by reliabl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116970</th>\n",
              "      <td>EVH Feature Photo\\n\\nAny strong opinions on th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  toxic\n",
              "24915   YOU ARE A FAT, GEEKY PRICK WHO HAS NOTHING TO ...      1\n",
              "75819   Agent X2: Basically thanks - with a 'little' m...      0\n",
              "53891   Why are my posts being deleted? \\n\\nI have tri...      0\n",
              "154159  \"\\n\\n Controlled Demolitions and Common Sense ...      0\n",
              "13040   I do not understand your reply.  //Blaxthos ( ...      0\n",
              "...                                                   ...    ...\n",
              "119965  FUCKASS  ople like him... Thanks. I hate peopl...      1\n",
              "149832  I agree, as much as humanly possible, to avoid...      0\n",
              "68147      REDIRECT Talk:Scooby-Doo! WrestleMania Mystery      0\n",
              "39863   \"\\n Not done: This is not supported by reliabl...      0\n",
              "116970  EVH Feature Photo\\n\\nAny strong opinions on th...      0\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIvPZK6U44pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a51b71-c4e7-465c-b458-c0fd3bd5400c"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    159571 non-null  object\n",
            " 1   toxic   159571 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDnG-vdNpKIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d85e8ea-14ee-4998-9fa0-094d86ce2ee5"
      },
      "source": [
        "print('Количество дублирующихся строк:', df.duplicated().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество дублирующихся строк: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9s_EwjflVzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa5ae43-78a9-43de-e791-d06e2890b907"
      },
      "source": [
        "df.toxic.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    143346\n",
              "1     16225\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDJHaSWgouim"
      },
      "source": [
        "В нашем распоряжении данные, состоящие из признака (комментарии) и целевого признака (лейбл токсичности комментария). Данные без пропусков, без дубликатов. Имеются мусорные спец.символы. имеется дисбаланс в лейблах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP6xAAjzqGzt"
      },
      "source": [
        "## Проведем стемминг и очистку текста от спец символов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFugc4k9qd1R"
      },
      "source": [
        "Лемматизацию сделать не получилось, так как процесс зависал или проходил более 12 часов без результата."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtAucHqcjXdQ"
      },
      "source": [
        "# def make_clear_text(text):\n",
        "#     clear_text = \" \".join(re.sub(r'[^a-zA-Z ]', ' ', text).split())\n",
        "#     return clear_text\n",
        "\n",
        "# df['text_lemma'] = (df['text'].apply(make_clear_text)).str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S11xQlJ444pw"
      },
      "source": [
        "# %%time\n",
        "# def make_lemmas(text):\n",
        "#     # Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\n",
        "#     nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "#     # Parse the sentence using the loaded 'en' model object `nlp`\n",
        "#     doc = nlp(text)\n",
        "#     # Extract the lemma for each token and join\n",
        "#     lemma = \" \".join([token.lemma_ for token in doc])\n",
        "#     return lemma\n",
        "#     #> 'the strip bat be hang on -PRON- foot for good'\n",
        "# df['text_lemma'] = (df['text_lemma'].apply(make_lemmas))\n",
        "\n",
        "# display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NflKZnmxsz-V"
      },
      "source": [
        "Проведем стемминг с очисткой от специальных символов (при помощи SnowballStemmer и регулярного выражения)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbjUGvU-44p5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "9bb0e152-3e0b-45a8-f070-2a4a483a58e2"
      },
      "source": [
        "%%time\n",
        "def make_clear_text(text):\n",
        "    clear_text = \" \".join(re.sub(r'[^a-zA-Z ]', ' ', text).split())\n",
        "    return clear_text\n",
        "\n",
        "df['text_stem'] = (df['text'].apply(make_clear_text))\n",
        "\n",
        "# def make_stem(text):\n",
        "#     english_stemmer = SnowballStemmer('english')\n",
        "\n",
        "#     stem_list = []\n",
        "#     for word in text.split():\n",
        "#         stem_list.append(english_stemmer.stem(word))\n",
        "#     stem = \" \".join(stem_list)\n",
        "#     return stem  \n",
        "\n",
        "# df['text_stem'] = df['text_stem'].apply(make_stem)\n",
        "\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>text_stem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24915</th>\n",
              "      <td>YOU ARE A FAT, GEEKY PRICK WHO HAS NOTHING TO ...</td>\n",
              "      <td>1</td>\n",
              "      <td>YOU ARE A FAT GEEKY PRICK WHO HAS NOTHING TO D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75819</th>\n",
              "      <td>Agent X2: Basically thanks - with a 'little' m...</td>\n",
              "      <td>0</td>\n",
              "      <td>Agent X Basically thanks with a little more Li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53891</th>\n",
              "      <td>Why are my posts being deleted? \\n\\nI have tri...</td>\n",
              "      <td>0</td>\n",
              "      <td>Why are my posts being deleted I have tried to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154159</th>\n",
              "      <td>\"\\n\\n Controlled Demolitions and Common Sense ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Controlled Demolitions and Common Sense recomm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13040</th>\n",
              "      <td>I do not understand your reply.  //Blaxthos ( ...</td>\n",
              "      <td>0</td>\n",
              "      <td>I do not understand your reply Blaxthos t c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119965</th>\n",
              "      <td>FUCKASS  ople like him... Thanks. I hate peopl...</td>\n",
              "      <td>1</td>\n",
              "      <td>FUCKASS ople like him Thanks I hate people lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149832</th>\n",
              "      <td>I agree, as much as humanly possible, to avoid...</td>\n",
              "      <td>0</td>\n",
              "      <td>I agree as much as humanly possible to avoid m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68147</th>\n",
              "      <td>REDIRECT Talk:Scooby-Doo! WrestleMania Mystery</td>\n",
              "      <td>0</td>\n",
              "      <td>REDIRECT Talk Scooby Doo WrestleMania Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39863</th>\n",
              "      <td>\"\\n Not done: This is not supported by reliabl...</td>\n",
              "      <td>0</td>\n",
              "      <td>Not done This is not supported by reliable sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116970</th>\n",
              "      <td>EVH Feature Photo\\n\\nAny strong opinions on th...</td>\n",
              "      <td>0</td>\n",
              "      <td>EVH Feature Photo Any strong opinions on the a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  ...                                          text_stem\n",
              "24915   YOU ARE A FAT, GEEKY PRICK WHO HAS NOTHING TO ...  ...  YOU ARE A FAT GEEKY PRICK WHO HAS NOTHING TO D...\n",
              "75819   Agent X2: Basically thanks - with a 'little' m...  ...  Agent X Basically thanks with a little more Li...\n",
              "53891   Why are my posts being deleted? \\n\\nI have tri...  ...  Why are my posts being deleted I have tried to...\n",
              "154159  \"\\n\\n Controlled Demolitions and Common Sense ...  ...  Controlled Demolitions and Common Sense recomm...\n",
              "13040   I do not understand your reply.  //Blaxthos ( ...  ...        I do not understand your reply Blaxthos t c\n",
              "...                                                   ...  ...                                                ...\n",
              "119965  FUCKASS  ople like him... Thanks. I hate peopl...  ...  FUCKASS ople like him Thanks I hate people lik...\n",
              "149832  I agree, as much as humanly possible, to avoid...  ...  I agree as much as humanly possible to avoid m...\n",
              "68147      REDIRECT Talk:Scooby-Doo! WrestleMania Mystery  ...      REDIRECT Talk Scooby Doo WrestleMania Mystery\n",
              "39863   \"\\n Not done: This is not supported by reliabl...  ...  Not done This is not supported by reliable sou...\n",
              "116970  EVH Feature Photo\\n\\nAny strong opinions on th...  ...  EVH Feature Photo Any strong opinions on the a...\n",
              "\n",
              "[50000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 682 ms, sys: 783 µs, total: 682 ms\n",
            "Wall time: 686 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P477ZvOfqsma"
      },
      "source": [
        "Текст очистили от мусорных символов.\n",
        "\n",
        "- Стемминг ухудшает качество модели, поэтому отключим его. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6PfMpgIr8bD"
      },
      "source": [
        "Разделим исходный данные на тренировочную и тестовую выборки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQqrSznk44qA"
      },
      "source": [
        "train, test = train_test_split(df, test_size = 0.1, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MG4j2PZsKWC"
      },
      "source": [
        "Создадам корпус слов, привядя к кодировки UTF-8 (признак) и целевой признак"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr7H-l9K44qI"
      },
      "source": [
        "corpus_train = train['text_stem'].values.astype('U')\n",
        "target_train = train['toxic']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcBTzVmesawf"
      },
      "source": [
        "Проведем кодирование (трансформирование) слов в цифровую матрицу.\n",
        "\n",
        "Оценка важности слова определяется величиной TF-IDF (от англ. term frequency, «частота терма, или слова»; inverse document frequency, «обратная частота документа, или текста»). То есть TF отвечает за количество упоминаний слова в отдельном тексте, а IDF отражает частоту его употребления во всём корпусе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pUyHaoiunRG"
      },
      "source": [
        "Мы будем использовать словарь стоп-слов, чтобы неприемлимые комментарии отправлялись на модерацию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8grVF2D44qM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9587327-7028-4123-88f8-426b6e0aacb1"
      },
      "source": [
        "%%time\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(nltk_stopwords.words('english'))\n",
        "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
        "\n",
        "tf_idf_train = count_tf_idf.fit_transform(corpus_train)\n",
        "\n",
        "corpus_test = test['text_stem'].values.astype('U')\n",
        "target_test = test['toxic']\n",
        "tf_idf_test = count_tf_idf.transform(corpus_test)\n",
        "tf_idf_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "CPU times: user 3.15 s, sys: 13.8 ms, total: 3.16 s\n",
            "Wall time: 3.29 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO5a1S1P44qR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6924d7-00be-4aa4-d0af-18e52c368b2a"
      },
      "source": [
        "print(\"Размер матрицы:\", tf_idf_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер матрицы: (143613, 158672)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF-EJVsV44p_"
      },
      "source": [
        "# 2. Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA0tFk1v44qA"
      },
      "source": [
        "## LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QmFAUI9u-MF"
      },
      "source": [
        "Обучим модель LogisticRegression, присвоим сбалансированноть весов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh-NLpzF44qW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53062b0-581c-4371-b763-e042a342dae8"
      },
      "source": [
        "%%time\n",
        "model_LogisticRegression = LogisticRegression(class_weight = 'balanced',\n",
        "                                              max_iter = 300,\n",
        "                                              penalty = 'l2',\n",
        "                                              # penalty = 'elasticnet', \n",
        "                                              C = 3.0,\n",
        "                                              # solver = 'saga',\n",
        "                                              # l1_ratio = 1,\n",
        "                                              random_state = 1,\n",
        "                                              n_jobs = -1)\n",
        "model_LogisticRegression.fit(tf_idf_train, target_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 21.8 ms, sys: 189 ms, total: 211 ms\n",
            "Wall time: 2.52 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwMLpYR9vLwE"
      },
      "source": [
        "Сделаем предсказания и вычислим метрику качесва модели F1-score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-cCVTOy44qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3208332-6087-4c42-eec6-8d0309504791"
      },
      "source": [
        "pred_train = model_LogisticRegression.predict(tf_idf_train)\n",
        "print('f1_score train:', f1_score(target_train, pred_train))\n",
        "pred_test = model_LogisticRegression.predict(tf_idf_test)\n",
        "print('f1_score test:', f1_score(target_test, pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score train: 0.915271033594292\n",
            "f1_score test: 0.7551202137132681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5t0PR37kDvg"
      },
      "source": [
        "### Вывод\n",
        "\n",
        "На логистической регресии мы получили качество F1-метрики:\n",
        "**f1_score test: 0.765**\n",
        "Это удовлетворяет условию задачи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJkn4av-44r-"
      },
      "source": [
        "## RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SzYhIV0vtEq"
      },
      "source": [
        "Подберем гиперпараметры модели RandomForestClassifier при помощи интсрумента GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JKJVKwZ44sA"
      },
      "source": [
        "# %%time\n",
        "# clf = RandomForestClassifier()\n",
        "\n",
        "# parameter_grid = {\n",
        "#             'max_depth': [3, 10, 50],\n",
        "#             'n_estimators': [100, 500, 1000]\n",
        "            \n",
        "#         }\n",
        "\n",
        "# grid_searcher = GridSearchCV(clf, parameter_grid, verbose=10)\n",
        "# grid_searcher.fit(tf_idf_train, target_train)\n",
        "# clf_best = grid_searcher.best_estimator_\n",
        " \n",
        "# print('Best params = ', clf_best.get_params())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfoe-iLqwBem"
      },
      "source": [
        "При обучении модели будем использовать параметры:\n",
        " max_depth = 50, n_estimators=100, random_state = 1, class_weight='balanced'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVdY8lh144sJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12dda01e-8de4-4f69-af23-4ded1f9511bb"
      },
      "source": [
        "%%time\n",
        "model_RandomForestClassifier = RandomForestClassifier(max_depth = 50, \n",
        "                                                      n_estimators=1000, \n",
        "                                                      random_state = 1, \n",
        "                                                      class_weight='balanced',\n",
        "                                                      n_jobs = -1)\n",
        "model_RandomForestClassifier.fit(tf_idf_train, target_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13min 14s, sys: 1.18 s, total: 13min 15s\n",
            "Wall time: 6min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVXkqfYE44sQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e158466a-507e-4ad4-9310-f2616de54d9a"
      },
      "source": [
        "pred_train = model_RandomForestClassifier.predict(tf_idf_train)\n",
        "print('f1_score train:', f1_score(target_train, pred_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score train: 0.5736238204903499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bOE-D6JV44sV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6b0c5a-af2e-4af8-a711-4b51a8f4efd7"
      },
      "source": [
        "pred_test = model_RandomForestClassifier.predict(tf_idf_test)\n",
        "print('f1_score test:', f1_score(target_test, pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score test: 0.488487750967029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ix31uYvyM_o"
      },
      "source": [
        "### Вывод\n",
        "\n",
        "На модели RandomForestClassifier мы получили качество F1-метрики:\n",
        "**f1_score test: 0.488** - это хуже, модели логистической регрессии."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n91OO1NmjKSn"
      },
      "source": [
        "## CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0fbchSUP8Nm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b7824d-0d6a-49c6-83ad-3d1c87541c7f"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/39/128fff65072c8327371e3c594f3c826d29c85b21cb6485980353b168e0e4/catboost-0.24.2-cp36-none-manylinux1_x86_64.whl (66.1MB)\n",
            "\u001b[K     |████████████████████████████████| 66.2MB 97kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2hiO3-kPaAq"
      },
      "source": [
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtWJcp8AQC8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e056849-cff3-4f52-ded2-1d4f3be79d43"
      },
      "source": [
        "%%time\n",
        "model_CatBoostClassifier = CatBoostClassifier(\n",
        "                                              iterations = 1000,\n",
        "                                              # n_estimators = 3000,\n",
        "                                              # class_weights=[0.1, 5],\n",
        "                                              auto_class_weights = 'Balanced',\n",
        "                                            #  task_type= 'GPU',\n",
        "                                             verbose=100)\n",
        "model_CatBoostClassifier.fit(tf_idf_train, target_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.085912\n",
            "0:\tlearn: 0.6537812\ttotal: 3.35s\tremaining: 55m 45s\n",
            "100:\tlearn: 0.3828162\ttotal: 4m 48s\tremaining: 42m 46s\n",
            "200:\tlearn: 0.3276968\ttotal: 9m 34s\tremaining: 38m 3s\n",
            "300:\tlearn: 0.2948485\ttotal: 14m 19s\tremaining: 33m 15s\n",
            "400:\tlearn: 0.2712125\ttotal: 19m 3s\tremaining: 28m 28s\n",
            "500:\tlearn: 0.2540586\ttotal: 23m 48s\tremaining: 23m 42s\n",
            "600:\tlearn: 0.2392379\ttotal: 28m 33s\tremaining: 18m 57s\n",
            "700:\tlearn: 0.2278687\ttotal: 33m 17s\tremaining: 14m 12s\n",
            "800:\tlearn: 0.2176246\ttotal: 38m 1s\tremaining: 9m 26s\n",
            "900:\tlearn: 0.2089369\ttotal: 42m 45s\tremaining: 4m 41s\n",
            "999:\tlearn: 0.2011025\ttotal: 47m 24s\tremaining: 0us\n",
            "CPU times: user 1h 27min 54s, sys: 28.3 s, total: 1h 28min 23s\n",
            "Wall time: 48min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9waJaK2QlZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc0cd93-be41-4a64-d447-91e14e06b1ae"
      },
      "source": [
        "pred_train = model_CatBoostClassifier.predict(tf_idf_train)\n",
        "print('f1_score train:', f1_score(target_train, pred_train))\n",
        "\n",
        "pred_test = model_CatBoostClassifier.predict(tf_idf_test)\n",
        "print('f1_score test:', f1_score(target_test, pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score train: 0.8204861004689367\n",
            "f1_score test: 0.7660979636763897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlYKfRZ3PZAD"
      },
      "source": [
        "### Вывод\n",
        "\n",
        "На модели СatBoostClassifier мы получили качество F1-метрики: **f1_score test: 0.766**. Обучение модели происходит довольно медленно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QoQQgnv44sk"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLZ9WHu6yeAE"
      },
      "source": [
        "Возьмем готовую модель BERT (от англ. Bidirectional Encoder Representations from Transformers, «двунаправленная нейронная сеть-кодировщик») — нейронная сеть для создания модели языка. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGMmpYLtyxd_"
      },
      "source": [
        "Из нашего датасета возьмем часть данных, так как мощность аппартных устройств (объём памяти GPU) не позволяет нам произвести обучение модели на полных данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4eEbHfs44sl"
      },
      "source": [
        "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n",
        "df = df.sample(n = 50000, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JELUbYf44sv"
      },
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['toxic'], \n",
        "                                                                    random_state=1, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    stratify=df['toxic'])\n",
        "\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=1, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAFY5Ed644s3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "89eca123f70e4a638982bb73e5943a7b",
            "6b992da334554af9b2d8c9aee825780a",
            "4b6834c550584645a28bcca03ea88460",
            "90760bca89de4d259ca6886026a85719",
            "e7801f84966246959321a1eb1dcf9444",
            "bce632e04e614c1884728d084a01422f",
            "6892fce594394d4e9445c23031b176b2",
            "d1a3d5666048405681f0be25996cbc49",
            "4cf6159251a24335a1d764d805a7d513",
            "487d77148bb24a58a362a6d4260d9980",
            "03616adac4d9413089321a30583328bd",
            "15b53eaeac8141f79a9147888f382653",
            "444699ccb73a4ba28bd5efe85de07690",
            "384e2517fd1646f0b5a9b30cf72b50fe",
            "24ad8a3610aa439ab7f4f4d0b947f45d",
            "0b0bad460383454eaedab2046a810124",
            "316534e3378a4fd0aa684bb17d3d5659",
            "ca54398238cd469a858a280c166e2a81",
            "efe566cf0ac843b5988dc30e08f6ce7e",
            "519b98f6ee9043ff8f3e8f6dced4aba7",
            "e978808800d24981805def710e4fb900",
            "72819b3c6d064642a6a3c7532d675f56",
            "a98a0aae76ae4eaa8806df70fcae6186",
            "9f5f3a56b12742e7a50ee5ace9f9f011",
            "b59af45011274f6abfa7058b66360f0c",
            "7d55415f92024d0287b04ca0d6e1ddfb",
            "da5877cc7c164274bc9c38d92aa43cdd",
            "6625d01831ee4b7e8bea4c6cda153fbd",
            "c3f0d293783746168a47578ebe49330b",
            "657855eddf0a43408dc87c5b6ac4fef4",
            "adbafa8e19e84b2d9f852171c9249368",
            "c91d50b238224ae29046936bd5bcec47"
          ]
        },
        "outputId": "424c82d7-cc56-4336-c2b1-15a301f8f512"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89eca123f70e4a638982bb73e5943a7b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cf6159251a24335a1d764d805a7d513",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "316534e3378a4fd0aa684bb17d3d5659",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b59af45011274f6abfa7058b66360f0c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieS0jsZY44tV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f032540-75fb-40cd-a499-2a88c414a771"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True)\n",
        "\n",
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkBoGUbF44te",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "795e55f8-aa59-496d-f04b-3e09297fa448"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)\n",
        "plt.title('Histogram of length of all the messages in the train set')\n",
        "plt.xlim(0, 200)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRsvnmM644tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210b1a51-9d94-40da-923d-a8802d1cb843"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 50,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 50,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 50,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhVV0ECt44tr"
      },
      "source": [
        "## convert lists to tensors\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gUMW1tM44tw"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIWZIGjW44t0"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1kmQ4pz44t4"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OvC5WDB44t9"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9FuujdD44uB"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5)          # learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7-aEu1P44uF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0d92fb-8fbe-4a81-87fa-da7fa390a2fa"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Weights: [0.55774004 4.82975127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seiWpx0H44uK"
      },
      "source": [
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 17"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmuTnJgX44uO"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95Y7Zx2c44uT"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      # elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enwJ9iVL44uW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "067642c9-5558-40ce-9d5d-ff6ece67418e"
      },
      "source": [
        "%%time\n",
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f9203078f07d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# set initial loss to infinite\\nbest_valid_loss = float('inf')\\n\\n# empty lists to store training and validation loss of each epoch\\ntrain_losses=[]\\nvalid_losses=[]\\n\\n#for each epoch\\nfor epoch in range(epochs):\\n     \\n    print('\\\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\\n    \\n    #train model\\n    train_loss, _ = train()\\n    \\n    #evaluate model\\n    valid_loss, _ = evaluate()\\n    \\n    #save the best model\\n    if valid_loss < best_valid_loss:\\n        best_valid_loss = valid_loss\\n        torch.save(model.state_dict(), 'saved_weights.pt')\\n    \\n    # append training and validation loss\\n    train_losses.append(train_loss)\\n    valid_losses.append(valid_loss)\\n    \\n    print(f'\\\\nTraining Loss: {train_loss:.3f}')\\n    print(f'Validation Loss: {valid_loss:.3f}')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-a8875e82e2a3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# get model predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# compute the loss between actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-9ebdcf410f97>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dim'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nRrsJKb44ua"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2i6Xvru44ug"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pvctOCt44un"
      },
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzDRMrD_44uy"
      },
      "source": [
        "print('f1_score test:', f1_score(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcxqk-TVmWlv"
      },
      "source": [
        "### Вывод\n",
        "Качество модели BERT **f1_score test: 0.543**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHIUWlsC44vN"
      },
      "source": [
        "# 3. Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfo0lXShL0im"
      },
      "source": [
        "Мы провели обучение моделей, которые ищут токсичные комментарии и отправляют их на модерацию.\n",
        "В результате обучения моделей мы получили следующие показатели метрики оценки качества F1 -score на тестовых данных:\n",
        "\n",
        "- LogisticRegression F1 - score: 0.76\n",
        "- RandomForestClassifier F1 - score: 0.48\n",
        "- СatBoostClassifier F1 - score: 0.76\n",
        "- BERT F1 - score: 0.54\n",
        "\n",
        "Для сайта мы предложим модель LogisticRegression, она показала высокое качество и быструю скорость обучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpmp1Hf9GEmn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
